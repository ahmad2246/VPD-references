# VPD-references
Visual Pollution Detection Using Deep Learning References
Welcome to the reference section of our project! Here, you can find a list of resources, papers, and materials related to our research.
[1] P. O. Ukaogo, U. Ewuzie, and C. V. Onwuka, ”Environmental pollution: causes, effects, and the remedies,” in Microorganisms for Sustainable Environment and Health, Eds. P. Chowdhary, A. Raj, D. Verma, and Y. Akhter, Elsevier, 2020, pp. 419-429, ISBN 9780128190012. [Online]. Available: https://doi.org/10.1016/B978-0-12-819001-2.00021-8.
[2] O. A. Alharbi and N. Rangel-Buitrago, ”Scenery evaluation as a tool for the determination of visual pollution in coastal environments: The Rabigh coastline, Kingdom of Saudi Arabia as a study case,” Marine Pollution Bulletin, vol. 181, pp. 113861, 2022.
[3] R. Fuller et al., ”Pollution and health: a progress update,” The Lancet Planetary Health, vol. 6, no. 6, pp. e535-e547, 2022. [Online]. Available: https://doi.org/10.1016/S2542-5196(22)00090-0.
[4] Y. LeCun, Y. Bengio, and G. Hinton, ”Deep learning,” Nature, vol. 521, pp. 436–444, May 2015.
[5] Z. Zou, K. Chen, Z. Shi, Y. Guo and J. Ye, ”Object Detection in 20 Years: A Survey,” in Proceedings of the IEEE, vol. 111, no. 3, pp. 257-276, March 2023, doi: 10.1109/JPROC.2023.3238524.
[6] Z. Wang, B. Jiao and L. Xu, ”Visual Object Detection: A Review,” 2021 40th Chinese Control Conference (CCC), Shanghai, China, 2021, pp. 7106-7112, doi: 10.23919/CCC52363.2021.9550689.
[7] M. Carranza-Garc´ıa, J. Torres-Mateo, P. Lara-Ben´ıtez, and J. Garc´ıa-Guti´errez, ”On the Performance of One-Stage and Two-Stage Object Detectors in Autonomous Vehicles Using Camera Data,” Remote Sens.,
vol. 13, no. 1, p. 89, 2021. [Online]. Available: https://doi.org/10.3390/rs13010089
[8] K. Chen, J. Li, W. Lin, J. See, J. Wang, L. Duan, et al., ”Towards accurate one-stage object detection with ap-loss,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 5119-5127.
[9] K. Chen, W. Lin, J. Li, J. See, J. Wang and J. Zou, ”AP-Loss for Accurate One-Stage Object Detection,” in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 43, no. 11, pp. 3782-3798, 1 Nov. 2021, doi: 10.1109/TPAMI.2020.2991457.
[10] R. Girshick, J. Donahue, T. Darrell and J. Malik, ”Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation,” 2014 IEEE Conference on Computer Vision and Pattern Recognition, Columbus, OH, USA, 2014, pp. 580-587, doi: 10.1109/CVPR.2014.81.
[11] R. Girshick, ”Fast R-CNN,” 2015 IEEE International Conference on Computer Vision (ICCV), Santiago, Chile, 2015, pp. 1440-1448, doi: 10.1109/ICCV.2015.169.
[12] S. Ren, K. He, R. Girshick, and J. Sun, ”Faster R-CNN: Towards real-time object detection with region proposal networks,” in Advances in Neural Information Processing Systems, vol. 28, 2015.
[13] J. Dai, Y. Li, K. He, and J. Sun, ”R-FCN: Object detection via region-based fully convolutional networks,” in Advances in Neural Information Processing Systems, vol. 29, 2016.
[14] T. Y. Lin, P. Doll´ar, R. Girshick, K. He, B. Hariharan, and S. Belongie, ”Feature pyramid networks for object detection,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2117-2125.
[15] K. He, G. Gkioxari, P. Doll´ar, and R. Girshick, ”Mask R-CNN,” in Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 2961-2969.
[16] Z. Cai and N. Vasconcelos, ”Cascade R-CNN: Delving into High Quality Object Detection,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 6154-6162.
[17] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, ”You Only Look Once: Unified, Real-Time Object Detection,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 779-788.
[18] G. Jocher, A. Chaurasia, and J. Qiu, ”YOLO by Ultralytics (Version 8.0.0) [Computer software],” 2023. [Online]. Available: https://github.com/ultralytics/ultralytics
[19] R. team, ”YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search,” [Online]. Available: https://deci.ai/blog/yolo-nas-object-detection-foundationmodel/. [Accessed: June 15, 2023].
[20] F. Kraus and K. Dietmayer, ”Uncertainty Estimation in One-Stage Object Detection,” 2019 IEEE Intelligent Transportation Systems Conference (ITSC), Auckland, New Zealand, 2019, pp. 53-60, doi: 10.1109/ITSC.2019.8917494.
[21] Zailan Nur Athirah, Azizan Muhammad Mokhzaini, Hasikin Khairunnisa, Mohd Khairuddin Anis Salwa, Khairuddin Uswah. (2022). ”An automated solid waste detection using the optimized YOLO model for riverine management.” Frontiers in Public Health, 10. doi: 10.3389/fpubh.2022.907280.
[22] M. Y. Hossain, I. R. Nijhum, A. A. Sadi, M. T. M. Shad and R. M. Rahman, ”Visual Pollution Detection Using Google Street View and YOLO,” 2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON), New York, NY, USA, 2021, pp. 0433-0440, doi: 10.1109/UEMCON53757.2021.9666654.
[23] L. Liu, B. Zhou, G. Liu, D. Lian and R. Zhang, ”Yolo-Based Multi-Model Ensemble for Plastic Waste Detection Along Railway Lines,” IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing
Symposium, Kuala Lumpur, Malaysia, 2022, pp. 7658-7661, doi: 10.1109/IGARSS46834.2022.9883308.
[24] R. Bawankule, V. Gaikwad, I. Kulkarni, S. Kulkarni, A. Jadhav and N. Ranjan, ”Visual Detection ofWaste using YOLOv8,” 2023 International Conference on Sustainable Computing and Smart Systems (ICSCSS), Coimbatore, India, 2023, pp. 869-873, doi: 10.1109/ICSCSS57650.2023.10169688.
[25] Technological Institute of the Philippines, ”YoloV7 - Trash Dataset V3 - 04/01/2023 Dataset,” Roboflow Universe, Roboflow, May 2023. [Online]. Available: https://universe.roboflow.com/ technological-institute-of-the-philippines/yolov7-trash-dataset-v3-04-01-2023. Visited on: August 11, 2023.
[26] R. Padilla, S. L. Netto and E. A. B. da Silva, ”A Survey on Performance Metrics for Object-Detection Algorithms,” 2020 International Conference on Systems, Signals and Image Processing (IWSSIP), Niteroi, Brazil, 2020, pp. 237-242, doi: 10.1109/IWSSIP48289.2020.9145130.
[27] J. Terven and D. Cordova-Esparza, ”A comprehensive review of YOLO: From YOLOv1 to YOLOv8 and beyond,” in arXiv preprint arXiv:2304.00501, 2023.
[28] N. Tatbul, T. J. Lee, S. Zdonik, M. Alam, and J. Gottschlich, ”Precision and recall for time series,” in Advances in Neural Information Processing Systems, vol. 31, 2018.
[29] Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio Savarese, ”Generalized intersection over union: A metric and a loss for bounding box regression,” in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019.
